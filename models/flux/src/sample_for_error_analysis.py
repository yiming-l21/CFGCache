import os
import re
import time
from dataclasses import dataclass
from glob import iglob

import numpy as np
import torch
from einops import rearrange
from PIL import ExifTags, Image
from transformers import pipeline
from tqdm import tqdm

from flux.sampling import denoise, get_noise, get_schedule, prepare, unpack, denoise_test_FLOPs
from flux.ideas import denoise_cache
from flux.util import configs, embed_watermark, load_ae, load_clip, load_flow_model, load_t5

NSFW_THRESHOLD = 0.85  # NSFW score threshold


@dataclass
class SamplingOptions:
    prompts: list[str]  # List of prompts
    width: int  # Image width
    height: int  # Image height
    num_steps: int  # Number of sampling steps
    guidance: float  # Guidance value
    seed: int | None  # Random seed
    num_images_per_prompt: int  # Number of images generated per prompt
    batch_size: int  # Batch size (batching of prompts)
    model_name: str  # Model name
    output_dir: str  # Output directory
    add_sampling_metadata: bool  # Whether to add metadata
    use_nsfw_filter: bool  # Whether to enable NSFW filter
    test_FLOPs: bool  # Whether in FLOPs test mode (no actual image generation)
    cache_mode: str  # Cache mode ('original', 'ToCa', 'Taylor', 'HiCache', 'Delta')
    interval: int  # Cache period length
    max_order: int  # Maximum order of Taylor expansion
    first_enhance: int  # Initial enhancement steps
    collect_features: bool  # Enable feature collection
    feature_layers: list[int]  # Feature collection layer indices (supports multiple layers)
    feature_module: str  # Feature collection module
    feature_stream: str  # Feature collection stream
    skip_decoding: bool  # Skip VAE decoding (feature collection only)
    feature_output_dir: str  # Feature output directory


def main(opts: SamplingOptions):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Optional NSFW classifier
    if opts.use_nsfw_filter:
        nsfw_classifier = pipeline(
            "image-classification", model="Falconsai/nsfw_image_detection", device=device
        )
    else:
        nsfw_classifier = None

    # Load model
    model_name = opts.model_name
    if model_name not in configs:
        available = ", ".join(configs.keys())
        raise ValueError(f"Unknown model name: {model_name}, available options: {available}")

    if opts.num_steps is None:
        opts.num_steps = 4 if model_name == "flux-schnell" else 50

    # Ensure width and height are multiples of 16
    opts.width = 16 * (opts.width // 16)
    opts.height = 16 * (opts.height // 16)

    # Set output directory and index
    output_name = os.path.join(opts.output_dir, f"img_{{idx}}.jpg")
    if not os.path.exists(opts.output_dir):
        os.makedirs(opts.output_dir)
    idx = 0  # Image index

    # Initialize model components
    torch_device = device

    # Load T5 and CLIP models to GPU
    t5 = load_t5(torch_device, max_length=256 if model_name == "flux-schnell" else 512)
    clip = load_clip(torch_device)

    # Load model to GPU
    model = load_flow_model(model_name, device=torch_device)
    ae = load_ae(model_name, device=torch_device)

    # Set random seed
    if opts.seed is not None:
        base_seed = opts.seed
    else:
        base_seed = torch.randint(0, 2**32, (1,)).item()

    prompts = opts.prompts

    total_images = len(prompts) * opts.num_images_per_prompt

    progress_bar = tqdm(total=total_images, desc="Generating images")

    # Compute number of prompt batches
    num_prompt_batches = (len(prompts) + opts.batch_size - 1) // opts.batch_size

    # ğŸ”¥ ä¿®å¤ï¼šæ·»åŠ å…¨å±€æ ·æœ¬è®¡æ•°å™¨ç”¨äºç‰¹å¾æ–‡ä»¶å‘½å
    sample_counter = 0

    for batch_idx in range(num_prompt_batches):
        prompt_start = batch_idx * opts.batch_size
        prompt_end = min(prompt_start + opts.batch_size, len(prompts))
        batch_prompts = prompts[prompt_start:prompt_end]
        num_prompts_in_batch = len(batch_prompts)

        # Generate corresponding number of images for each prompt
        for image_idx in range(opts.num_images_per_prompt):
            # Prepare random seed
            seed = base_seed + idx  # Assign a different seed for each image
            idx += num_prompts_in_batch  # Update image index

            # Prepare input
            batch_size = num_prompts_in_batch
            x = get_noise(
                batch_size,
                opts.height,
                opts.width,
                device=torch_device,
                dtype=torch.bfloat16,
                seed=seed,
            )

            # Prepare prompts
            # batch_prompts is a list containing the prompts in the current batch
            inp = prepare(t5, clip, x, prompt=batch_prompts)
            timesteps = get_schedule(
                opts.num_steps, inp["img"].shape[1], shift=(model_name != "flux-schnell")
            )

            # Denoising
            with torch.no_grad():
                if opts.test_FLOPs:
                    x = denoise_test_FLOPs(
                        model, **inp, timesteps=timesteps, guidance=opts.guidance, cache_mode=opts.cache_mode
                    )
                else:
                    # ğŸ”¥ é…ç½®ç‰¹å¾æ”¶é›†ï¼ˆæ”¯æŒå¤šæ¨¡å—ä¸€æ¬¡æ€§æ”¶é›†ï¼‰
                    feature_config = None
                    if opts.collect_features:
                        feature_config = {
                            "target_layers": opts.feature_layers,
                            "target_modules": ["any"],  # æ”¯æŒå¤šæ¨¡å—åˆ—è¡¨
                            "target_streams": ["any"],  # æ”¯æŒå¤šæµåˆ—è¡¨
                        }

                    x = denoise_cache(
                        model,
                        **inp,
                        timesteps=timesteps,
                        guidance=opts.guidance,
                        cache_mode=opts.cache_mode,
                        interval=opts.interval,
                        max_order=opts.max_order,
                        first_enhance=opts.first_enhance,
                        # ğŸ”¥ åˆ©ç”¨ç°æœ‰çš„ç‰¹å¾æ”¶é›†ç³»ç»Ÿ
                        enable_feature_collection=opts.collect_features,
                        feature_collection_config=feature_config,
                    )

                    # ğŸ”¥ æ­¥éª¤ 1: å¦‚æœéœ€è¦ï¼Œæ”¶é›†ç‰¹å¾åˆ°å†…å­˜
                    if opts.collect_features:
                        from flux.taylor_utils import get_collected_features

                        features, metadata = get_collected_features(model._last_cache_dic)
                        # ä¿å­˜ç‰¹å¾æ•°æ®
                        save_multi_module_features(features, metadata, opts.prompts, opts, sample_counter)

                    # ğŸ”¥ æ­¥éª¤ 2: å¦‚æœéœ€è¦ï¼Œè¿›è¡Œè§£ç å’Œæ ·æœ¬ä¿å­˜
                    if not opts.skip_decoding:
                        # è§£ç 
                        decoded_x = unpack(x.float(), opts.height, opts.width)
                        with torch.autocast(device_type=torch_device.type, dtype=torch.bfloat16):
                            decoded_x = ae.decode(decoded_x)

                        # ä¿å­˜æ ·æœ¬äº§ç‰© (å›¾ç‰‡å’Œ prompt)
                        save_sample_artifacts(decoded_x, batch_prompts, opts, sample_counter, nsfw_classifier)

            # æ›´æ–°å…¨å±€æ ·æœ¬è®¡æ•°å™¨ (æ— è®ºå“ªç§æ¨¡å¼ï¼Œä¸€ä¸ª prompt å°±ç®—ä¸€ä¸ªæ ·æœ¬)
            sample_counter += num_prompts_in_batch

            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.update(num_prompts_in_batch)

    progress_bar.close()


def save_sample_artifacts(decoded_images, prompts, opts: SamplingOptions, start_image_idx, nsfw_classifier):
    """
    ä¿å­˜æ ·æœ¬çš„ä¸Šä¸‹æ–‡äº§ç‰© (å›¾ç‰‡å’Œ prompt) åˆ°å…¨å±€çš„ samples ç›®å½•ã€‚
    """
    import os
    from PIL import ExifTags, Image

    # ç¡®ä¿å…¨å±€æ ·æœ¬ç›®å½•å­˜åœ¨
    samples_base_dir = os.path.join(opts.feature_output_dir, "samples")
    os.makedirs(samples_base_dir, exist_ok=True)

    # æ ¼å¼åŒ–å›¾åƒå¼ é‡
    decoded_images = decoded_images.clamp(-1, 1)
    decoded_images = embed_watermark(decoded_images.float())
    decoded_images = rearrange(decoded_images, "b c h w -> b h w c")

    # éå†æ‰¹æ¬¡ä¸­çš„æ¯ä¸ªæ ·æœ¬
    for i in range(decoded_images.shape[0]):
        current_sample_idx = start_image_idx + i

        # åˆ›å»ºè¯¥æ ·æœ¬çš„ä¸“å±ç›®å½•
        sample_dir = os.path.join(samples_base_dir, f"sample_{current_sample_idx+1:03d}")
        os.makedirs(sample_dir, exist_ok=True)

        # 1. ä¿å­˜å›¾ç‰‡
        img_array = decoded_images[i]
        img = Image.fromarray((127.5 * (img_array + 1.0)).cpu().numpy().astype(np.uint8))

        # å¯é€‰çš„ NSFW è¿‡æ»¤
        if opts.use_nsfw_filter and nsfw_classifier:
            nsfw_result = nsfw_classifier(img)
            nsfw_score = next((res["score"] for res in nsfw_result if res["label"] == "nsfw"), 0.0)
        else:
            nsfw_score = 0.0

        if nsfw_score < NSFW_THRESHOLD:
            image_path = os.path.join(sample_dir, "image.png")
            exif_data = Image.Exif()
            exif_data[ExifTags.Base.Software] = "AI generated;txt2img;flux"
            exif_data[ExifTags.Base.Make] = "Black Forest Labs"
            exif_data[ExifTags.Base.Model] = opts.model_name
            exif_data[ExifTags.Base.ImageDescription] = prompts[i]
            img.save(image_path, exif=exif_data, quality=95)
            print(f"   ğŸ–¼ï¸  æ ·æœ¬å›¾ç‰‡å·²ä¿å­˜: {image_path}")
        else:
            print(f"   âš ï¸  æ ·æœ¬ {current_sample_idx+1} å¯èƒ½åŒ…å«ä¸å½“å†…å®¹ï¼Œå·²è·³è¿‡å›¾ç‰‡ä¿å­˜ã€‚")

        # 2. ä¿å­˜ Prompt
        prompt_path = os.path.join(sample_dir, "prompt.txt")
        with open(prompt_path, "w", encoding="utf-8") as f:
            f.write(prompts[i])
        print(f"   ğŸ“ æ ·æœ¬ Prompt å·²ä¿å­˜: {prompt_path}")


def read_prompts(prompt_file: str):
    with open(prompt_file, "r", encoding="utf-8") as f:
        prompts = [line.strip() for line in f if line.strip()]
    return prompts


def save_multi_module_features(features, metadata, prompts, opts: SamplingOptions, image_idx):
    """
    ä¿å­˜å¤šæ¨¡å—ç‰¹å¾ - ä½¿ç”¨å‚æ•°åŒ–çš„ç›®å½•ç»“æ„

    Args:
        features: åµŒå¥—å­—å…¸ {layer_idx: {module_name: [feature_tensors]}}
        metadata: åµŒå¥—å­—å…¸ {layer_idx: {module_name: [metadata_dicts]}}
        prompts: æç¤ºåˆ—è¡¨
        opts: åŒ…å«æ‰€æœ‰é‡‡æ ·é€‰é¡¹çš„ SamplingOptions å¯¹è±¡
        image_idx: å›¾åƒç´¢å¼•
    """
    import pickle
    import os
    from datetime import datetime

    output_base_dir = opts.feature_output_dir
    if output_base_dir is None:
        output_base_dir = "./features"  # é»˜è®¤åŸºç¡€ç›®å½•

    saved_files = []

    print(f"ğŸ”„ å¼€å§‹ä¿å­˜å‚æ•°åŒ–ç‰¹å¾ (æ ·æœ¬ {image_idx})...")

    # éå†æ¯ä¸ªå±‚
    for layer_idx, layer_data in features.items():
        # æ„å»ºåŸºç¡€è·¯å¾„ï¼Œä¸å†åŒ…å«æ­¥æ•°ä¿¡æ¯
        base_path = os.path.join(output_base_dir, opts.model_name, f"l_{layer_idx}")

        # å‘åå…¼å®¹ï¼šå¤„ç†æ—§æ ¼å¼çš„å•å±‚æ•°æ®
        if not isinstance(layer_data, dict):
            os.makedirs(base_path, exist_ok=True)
            filename = f"trajectory_sample_{image_idx+1:03d}.pkl"
            filepath = os.path.join(base_path, filename)

            # ... (æ—§çš„ä¿å­˜é€»è¾‘) ...
            with open(filepath, "wb") as f:
                pickle.dump({}, f)  # ç®€åŒ–
            saved_files.append(filepath)
            continue

        # å¤„ç†æ–°æ ¼å¼ï¼šéå†æ¯ä¸ªæ¨¡å—
        for module_name, module_features in layer_data.items():
            # å•æµæ¨¡å—ï¼ˆå¦‚ layer 28ï¼‰ä¸åˆ›å»ºæ¨¡å—å­ç›®å½•
            if module_name == "total":
                module_output_dir = base_path
            else:
                # å¤šæµæ¨¡å—ï¼ˆå¦‚ layer 14ï¼‰åˆ›å»ºæ¨¡å—å­ç›®å½•
                module_output_dir = os.path.join(base_path, f"m_{module_name}")

            os.makedirs(module_output_dir, exist_ok=True)

            # ä¿å­˜æ¨¡å—ç‰¹å¾
            filename = f"trajectory_sample_{image_idx+1:03d}.pkl"
            filepath = os.path.join(module_output_dir, filename)

            module_metadata = metadata.get(layer_idx, {}).get(module_name, [])

            data = {
                # ä¸å†ä¿å­˜ promptï¼Œå› ä¸ºå®ƒåœ¨å…¨å±€æ ·æœ¬ç›®å½•ä¸­
                "features": module_features,
                "metadata": module_metadata,
                "layer": layer_idx,
                "module": module_name,
                "feature_shape": str(module_features[0].shape) if module_features else "empty",
                "num_timesteps": len(module_features),
                "image_idx": image_idx,
                "timestamp": datetime.now().isoformat(),
            }

            with open(filepath, "wb") as f:
                pickle.dump(data, f)

            saved_files.append(filepath)
            print(f"   âœ… L{layer_idx}-M:{module_name} -> {module_output_dir}")

    print(f"ğŸ“ æ€»è®¡ä¿å­˜ {len(saved_files)} ä¸ªæ¨¡å—ç‰¹å¾æ–‡ä»¶")
    return saved_files


def save_trajectory_features(features, metadata, prompts, output_dir, image_idx):
    """
    ä¿å­˜è½¨è¿¹ç‰¹å¾åˆ°æ–‡ä»¶ - å…¼å®¹æ—§ç‰ˆæœ¬ï¼Œä½†æ¨èä½¿ç”¨ save_multi_module_features

    Args:
        features: ç‰¹å¾å­—å…¸ï¼Œé”®ä¸ºå±‚ç´¢å¼•
        metadata: å…ƒæ•°æ®å­—å…¸ï¼Œé”®ä¸ºå±‚ç´¢å¼•
        prompts: æç¤ºåˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        image_idx: å›¾åƒç´¢å¼•
    """
    import pickle
    import os
    from datetime import datetime

    if output_dir is None:
        output_dir = "./golden_trajectories"

    os.makedirs(output_dir, exist_ok=True)

    # ä¸ºæ¯ä¸ªå›¾åƒæ‰¹æ¬¡åˆ›å»ºå•ç‹¬çš„æ–‡ä»¶
    filename = f"trajectory_batch_{image_idx:03d}.pkl"
    filepath = os.path.join(output_dir, filename)

    data = {
        "features": features,
        "metadata": metadata,
        "prompts": prompts,
        "image_idx": image_idx,
        "timestamp": datetime.now().isoformat(),
    }

    with open(filepath, "wb") as f:
        pickle.dump(data, f)

    print(f"ç‰¹å¾è½¨è¿¹å·²ä¿å­˜åˆ°: {filepath}")

    # ç»Ÿè®¡æ¯å±‚çš„ç‰¹å¾æ•°é‡
    if isinstance(features, dict):
        for layer_idx, layer_features in features.items():
            if isinstance(layer_features, dict):
                # æ–°æ ¼å¼ï¼šå¤šæ¨¡å—
                for module_name, module_data in layer_features.items():
                    print(f"  Layer {layer_idx} - {module_name}: æ”¶é›†äº† {len(module_data)} ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾")
            else:
                # æ—§æ ¼å¼ï¼šå•æ¨¡å—
                print(f"  Layer {layer_idx}: æ”¶é›†äº† {len(layer_features)} ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾")
    else:
        # å‘åå…¼å®¹ï¼šå¦‚æœfeaturesæ˜¯åˆ—è¡¨ï¼ˆæ—§æ ¼å¼ï¼‰
        print(f"æ”¶é›†äº† {len(features)} ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾")

    return filepath


def app():
    import argparse

    parser = argparse.ArgumentParser(description="Generate images using the flux model.")
    parser.add_argument("--prompt_file", type=str, required=True, help="Path to the prompt text file.")
    parser.add_argument("--width", type=int, default=1024, help="Width of the generated image.")
    parser.add_argument("--height", type=int, default=1024, help="Height of the generated image.")
    parser.add_argument("--num_steps", type=int, default=None, help="Number of sampling steps.")
    parser.add_argument("--guidance", type=float, default=3.5, help="Guidance value.")
    parser.add_argument("--seed", type=int, default=0, help="Random seed.")
    parser.add_argument("--num_images_per_prompt", type=int, default=1, help="Number of images per prompt.")
    parser.add_argument("--batch_size", type=int, default=1, help="Batch size (prompt batching).")
    parser.add_argument(
        "--model_name",
        type=str,
        default="flux-schnell",
        choices=["flux-dev", "flux-schnell"],
        help="Model name.",
    )
    parser.add_argument("--output_dir", type=str, default="./samples", help="Directory to save images.")
    parser.add_argument(
        "--add_sampling_metadata", action="store_true", help="Whether to add prompt metadata to images."
    )
    parser.add_argument("--use_nsfw_filter", action="store_true", help="Enable NSFW filter.")
    parser.add_argument("--test_FLOPs", action="store_true", help="Test inference computation cost.")
    parser.add_argument(
        "--cache_mode",
        type=str,
        default="original",
        choices=[
            "original",
            "ToCa",
            "Taylor",
            "Taylor-Scaled",
            "HiCache",
            "Delta",
            "collect",
            "ClusCa",
            "Hi-ClusCa",
        ],
        help="Cache mode for denoising.",
    )
    parser.add_argument("--interval", type=int, default=10, help="Cache period length.")
    parser.add_argument("--max_order", type=int, default=1, help="Maximum order of Taylor expansion.")
    parser.add_argument("--first_enhance", type=int, default=3, help="Initial enhancement steps.")
    parser.add_argument("--collect_features", action="store_true", help="Enable feature collection mode.")
    parser.add_argument(
        "--feature_layers",
        type=int,
        nargs="+",
        default=[14],
        help="Feature collection layer indices (supports multiple layers).",
    )
    parser.add_argument(
        "--feature_layer",
        type=int,
        help="Feature collection layer index (legacy, for backward compatibility).",
    )
    parser.add_argument("--feature_module", type=str, default="total", help="Feature collection module.")
    parser.add_argument(
        "--feature_stream", type=str, default="single_stream", help="Feature collection stream."
    )
    parser.add_argument(
        "--skip_decoding", action="store_true", help="Skip VAE decoding (feature collection only)."
    )
    parser.add_argument(
        "--feature_output_dir", type=str, default="./golden_trajectories", help="Feature output directory."
    )

    args = parser.parse_args()

    prompts = read_prompts(args.prompt_file)

    # Handle legacy feature_layer parameter for backward compatibility
    feature_layers = args.feature_layers
    if args.feature_layer is not None:
        feature_layers = [args.feature_layer]

    opts = SamplingOptions(
        prompts=prompts,
        width=args.width,
        height=args.height,
        num_steps=args.num_steps,
        guidance=args.guidance,
        seed=args.seed,
        num_images_per_prompt=args.num_images_per_prompt,
        batch_size=args.batch_size,
        model_name=args.model_name,
        output_dir=args.output_dir,
        add_sampling_metadata=args.add_sampling_metadata,
        use_nsfw_filter=args.use_nsfw_filter,
        test_FLOPs=args.test_FLOPs,
        cache_mode=args.cache_mode,
        interval=args.interval,
        max_order=args.max_order,
        first_enhance=args.first_enhance,
        collect_features=args.collect_features,
        feature_layers=feature_layers,
        feature_module=args.feature_module,
        feature_stream=args.feature_stream,
        skip_decoding=args.skip_decoding,
        feature_output_dir=args.feature_output_dir,
    )

    main(opts)


if __name__ == "__main__":
    app()
